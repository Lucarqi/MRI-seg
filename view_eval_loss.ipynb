{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-1.2770, -0.0365],\n",
      "          [ 0.8504, -0.7955]],\n",
      "\n",
      "         [[ 0.3952, -3.0420],\n",
      "          [-1.3678, -0.3908]],\n",
      "\n",
      "         [[ 1.3928, -0.3926],\n",
      "          [ 0.3143,  0.3294]],\n",
      "\n",
      "         [[ 1.0659,  0.0909],\n",
      "          [-1.7372,  0.5128]]],\n",
      "\n",
      "\n",
      "        [[[-0.6215, -0.9318],\n",
      "          [-1.7554, -0.2766]],\n",
      "\n",
      "         [[ 0.5350, -0.2120],\n",
      "          [ 0.2825, -0.1146]],\n",
      "\n",
      "         [[ 1.2075, -0.9873],\n",
      "          [-1.2648, -1.0124]],\n",
      "\n",
      "         [[ 0.1733,  1.5250],\n",
      "          [-1.2210, -1.4409]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2667, -2.1353],\n",
      "          [ 0.3502,  1.4354]],\n",
      "\n",
      "         [[-0.8154,  1.2190],\n",
      "          [ 0.9452, -1.2289]],\n",
      "\n",
      "         [[-0.3375, -1.1769],\n",
      "          [-0.5800,  0.4827]],\n",
      "\n",
      "         [[ 0.8081, -0.7388],\n",
      "          [ 0.8396,  1.0868]]]])\n",
      "torch.Size([3, 4, 2, 2])\n",
      "tensor([[[[2, 3],\n",
      "          [0, 3]]],\n",
      "\n",
      "\n",
      "        [[[2, 3],\n",
      "          [1, 1]]],\n",
      "\n",
      "\n",
      "        [[[3, 1],\n",
      "          [1, 0]]]])\n",
      "torch.Size([3, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "from EvalAndLoss import onehot2index\n",
    "import torch\n",
    "onehot = torch.randn(3,4,2,2)\n",
    "print(onehot)\n",
    "print(onehot.shape)\n",
    "index = onehot2index(onehot)\n",
    "print(index)\n",
    "print(index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 假设输出一个 [batch_size=2, channel=1, height=2, width=2] 格式的张量 x1\n",
    "x1 = torch.tensor(\n",
    "    [[[[ 0.43, -0.25],\n",
    "        [-0.32, 0.69]]],\n",
    "\n",
    "        [[[-0.29, 0.37],\n",
    "          [0.54,  -0.72]]]])\n",
    "\n",
    "# 假设标签图像为与 x1 同型的张量 y1\n",
    "y1 = torch.tensor(\n",
    "    [[[[0., 0.],\n",
    "        [0., 1.]]],\n",
    "\n",
    "        [[[0., 0.],\n",
    "          [1.,  1.]]]])\n",
    "print(x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.6059, 0.4378],\n",
       "          [0.4207, 0.6660]]],\n",
       "\n",
       "\n",
       "        [[[0.4280, 0.5915],\n",
       "          [0.6318, 0.3274]]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = torch.sigmoid(x1)\n",
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 2, 2])\n",
      "tensor([[[[0.9311, 0.5759],\n",
      "          [0.5459, 0.4065]]],\n",
      "\n",
      "\n",
      "        [[[0.5586, 0.8952],\n",
      "          [0.4592, 1.1166]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.6861)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.交叉熵计算\n",
    "loss_cal = -1*(y1*torch.log(s1)+(1-y1)*torch.log(1-s1)) # 此处相当于一个one-hot编码\n",
    "print(loss_cal.shape)\n",
    "print(loss_cal)\n",
    "loss_cal_mean = torch.mean(loss_cal)\n",
    "loss_cal_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 2, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4113/3830234296.py:16: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  y1 = torch.LongTensor([[[0., 1.],\n"
     ]
    }
   ],
   "source": [
    "# 假设输出一个[batch_size=2, channel=2, height=2, width=2]格式的张量 x1\n",
    "x1 = torch.tensor([[[[ 0.3164, -0.1922],\n",
    "          [ 0.4326, -1.2193]],\n",
    "\n",
    "         [[ 0.6873,  0.6838],\n",
    "          [ 0.2244,  0.5615]]],\n",
    "\n",
    "\n",
    "        [[[-0.2516, -0.8875],\n",
    "          [-0.6289, -0.1796]],\n",
    "\n",
    "         [[ 0.0411, -1.7851],\n",
    "          [-0.3069, -1.0379]]]])\n",
    "\n",
    "# 假设标签图像为与x1同型，然后去掉channel的张量 y1 （注意两点，channel没了，格式为LongTensor）\n",
    "y1 = torch.LongTensor([[[0., 1.],\n",
    "         [1., 0.]],\n",
    "\n",
    "        [[1., 1.],\n",
    "         [0., 1.]]])\n",
    "y1_one_hot = torch.zeros_like(x1).scatter_(dim=1,index=y1.unsqueeze(dim=1),src=torch.ones_like(x1))\n",
    "y1_one_hot\n",
    "print(y1_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.8957, 0.3482],\n",
      "         [0.8027, 1.9365]],\n",
      "\n",
      "        [[0.5575, 1.2394],\n",
      "         [0.8671, 1.2117]]])\n",
      "tensor([[[0.5300, 0.1024],\n",
      "         [0.4430, 1.6573]],\n",
      "\n",
      "        [[0.2382, 0.8806],\n",
      "         [0.5027, 0.8510]]])\n"
     ]
    }
   ],
   "source": [
    "loss_ce = torch.nn.CrossEntropyLoss(reduction='none')(x1,y1)\n",
    "print(loss_ce)\n",
    "from eval_loss import *\n",
    "loss_my = CrossEntropyLoss()(x1,y1_one_hot)\n",
    "focal = FocalLoss(gamma=1,reduction='none')(x1,y1_one_hot)\n",
    "print(focal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 0.],\n",
      "          [0., 1.]],\n",
      "\n",
      "         [[0., 1.],\n",
      "          [1., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0.],\n",
      "          [1., 0.]],\n",
      "\n",
      "         [[1., 1.],\n",
      "          [0., 1.]]]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4113/2040371511.py:15: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  y1 = torch.LongTensor([[[0., 1.],\n"
     ]
    }
   ],
   "source": [
    "# test Dice loss\n",
    "x1 = torch.tensor([[[[ 0.3164, -0.1922],\n",
    "          [ 0.4326, -1.2193]],\n",
    "\n",
    "         [[ 0.6873,  0.6838],\n",
    "          [ 0.2244,  0.5615]]],\n",
    "\n",
    "\n",
    "        [[[-0.2516, -0.8875],\n",
    "          [-0.6289, -0.1796]],\n",
    "\n",
    "         [[ 0.0411, -1.7851],\n",
    "          [-0.3069, -1.0379]]]])\n",
    "# 假设标签图像为与x1同型，然后去掉channel的张量 y1 （注意两点，channel没了，格式为LongTensor）\n",
    "y1 = torch.LongTensor([[[0., 1.],\n",
    "         [1., 0.]],\n",
    "\n",
    "        [[1., 1.],\n",
    "         [0., 1.]]])\n",
    "y1_one_hot = torch.zeros_like(x1).scatter_(dim=1,index=y1.unsqueeze(dim=1),src=torch.ones_like(x1))\n",
    "print(y1_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4083, 0.2940],\n",
      "         [0.5519, 0.1442]],\n",
      "\n",
      "        [[0.4273, 0.7105],\n",
      "         [0.4202, 0.7023]]])\n",
      "tensor([[[1., 0.],\n",
      "         [0., 1.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [1., 0.]]])\n",
      "tensor(0.5447)\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "dice = BinaryDiceLoss(reduction='mean')\n",
    "predict = torch.nn.functional.softmax(x1,dim=1)\n",
    "print(predict[:,0])\n",
    "print(y1_one_hot[:,0])\n",
    "loss = dice(predict[:,0],y1_one_hot[:,0])\n",
    "print(loss)\n",
    "print(loss.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('d2l')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "94355fb3ca2c023cd20685028b68c25ab54b218726b4fe441f3362a985e6f225"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
